{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "# from models.cvt import CvT, EqCvT\n",
    "from typing import *\n",
    "from utils.util import (\n",
    "    make_directories,\n",
    "    seed_everything,\n",
    "    get_device,\n",
    "    init_logging_handler,\n",
    ")\n",
    "from utils.dataset import download_dataset, DeepLenseDataset, visualize_samples\n",
    "from utils.train import train\n",
    "from utils.inference import Inference\n",
    "from argparse import ArgumentParser\n",
    "from config.data_config import DATASET\n",
    "from config.eqcvt_config import EQCVT_CONFIG\n",
    "from config.pretrained_config import PRETRAINED_CONFIG\n",
    "from utils.augmentation import get_transform_test, get_transform_train\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from torchvision import models\n",
    "from models.cnn_zoo import Model, ConViT\n",
    "import math\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from models.transformer_zoo import (\n",
    "    GetCrossFormer,\n",
    "    GetTwinsSVT,\n",
    "    GetLeViT,\n",
    "    GetPiT,\n",
    "    GetCCT,\n",
    "    GetT2TViT,\n",
    "    TransformerModels,\n",
    ")\n",
    "\n",
    "from config.cct_config import CCT_CONFIG\n",
    "from config.twinssvt_config import TWINSSVT_CONFIG\n",
    "from config.levit_config import LEVIT_CONFIG\n",
    "from config.cait_config import CAIT_CONFIG\n",
    "from config.crossvit_config import CROSSVIT_CONFIG\n",
    "from config.pit_config import PIT_CONFIG\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in the case of Colab only\n",
    "# %%bash\n",
    "# set -m\n",
    "# git clone https://github.com/sachdevkartik/GSoC-2022.git\n",
    "# mv GSoC-2022/* . \n",
    "# rm -rf GSoC-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the dataset, ROC curve and confusion matrix:\n",
    "# Please comment out: matplotlib.use(\"Agg\") from utils/inference.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Model_II\"\n",
    "dataset_dir = \"data\"\n",
    "use_cuda = True\n",
    "num_workers = 10\n",
    "train_config_name = \"TwinsSVT\"\n",
    "\n",
    "classes = DATASET[f\"{dataset_name}\"][\"classes\"]\n",
    "\n",
    "if train_config_name == \"CCT\":\n",
    "    train_config = CCT_CONFIG\n",
    "elif train_config_name == \"TwinsSVT\":\n",
    "    train_config = TWINSSVT_CONFIG\n",
    "elif train_config_name == \"LeViT\":\n",
    "    train_config = LEVIT_CONFIG\n",
    "elif train_config_name == \"CaiT\":\n",
    "    train_config = CAIT_CONFIG\n",
    "elif train_config_name == \"CrossViT\":\n",
    "    train_config = CROSSVIT_CONFIG\n",
    "elif train_config_name == \"PiT\":\n",
    "    train_config = PIT_CONFIG\n",
    "else:\n",
    "    train_config = CCT_CONFIG  # temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = train_config[\"network_type\"]\n",
    "network_config = train_config[\"network_config\"]\n",
    "image_size = train_config[\"image_size\"]\n",
    "optimizer_config = train_config[\"optimizer_config\"]\n",
    "lr_schedule_config = train_config[\"lr_schedule_config\"]\n",
    "\n",
    "make_directories([dataset_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_II dataset already exists\n"
     ]
    }
   ],
   "source": [
    "trainset = DeepLenseDataset(\n",
    "    dataset_dir,\n",
    "    \"train\",\n",
    "    dataset_name,\n",
    "    transform=get_transform_train(\n",
    "        upsample_size=387,\n",
    "        final_size=train_config[\"image_size\"],\n",
    "        channels=train_config[\"channels\"],\n",
    "    ),\n",
    "    download=True,\n",
    "    channels=train_config[\"channels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.25\n",
    "valid_len = int(split_ratio * len(trainset))\n",
    "train_len = len(trainset) - valid_len\n",
    "trainset, testset = random_split(trainset, [train_len, valid_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed=42)\n",
    "device = get_device(use_cuda=use_cuda, cuda_idx=0)\n",
    "\n",
    "# logging\n",
    "current_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "log_dir_base = \"logger\"\n",
    "log_dir = f\"{log_dir_base}/{current_time}\"\n",
    "init_logging_handler(log_dir_base, current_time)\n",
    "\n",
    "PATH = os.path.join(\n",
    "    f\"{log_dir}/checkpoint\", f\"{network_type}_{dataset_name}_{current_time}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=trainset,\n",
    "    batch_size=train_config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=testset,\n",
    "    batch_size=train_config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(train_loader))\n",
    "print(sample[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartik/git/GSoC-2022/utils/dataset.py:196: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "visualize_samples(dataset=trainset, labels_map=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = len(classes)  # number of classes to be classified\n",
    "print(num_classes)\n",
    "print(f\"Train Data: {len(trainset)}\")\n",
    "print(f\"Val Data: {len(testset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model\n",
    "model = TransformerModels(\n",
    "    transformer_type=train_config[\"network_type\"],\n",
    "    num_channels=train_config[\"channels\"],\n",
    "    num_classes=num_classes,\n",
    "    img_size=image_size,\n",
    "    **train_config[\"network_config\"],\n",
    ")\n",
    "\n",
    "summary(model, input_size=(train_config[\"batch_size\"], 1, image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=optimizer_config[\"lr\"],\n",
    "    weight_decay=optimizer_config[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "epochs = train_config[\"num_epochs\"]\n",
    "warmup_epochs = optimizer_config[\"warmup_epoch\"]\n",
    "num_train_steps = math.ceil(len(train_loader))\n",
    "num_warmup_steps = num_train_steps * warmup_epochs\n",
    "num_training_steps = int(num_train_steps * epochs)\n",
    "\n",
    "# learning rate scheduler\n",
    "cosine_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config[\"dataset_name\"] = dataset_name\n",
    "train_config[\"lr_schedule_config\"][\"cosine_scheduler\"] = {}\n",
    "train_config[\"lr_schedule_config\"][\"cosine_scheduler\"][\n",
    "    \"num_warmup_steps\"\n",
    "] = num_warmup_steps\n",
    "train_config[\"lr_schedule_config\"][\"cosine_scheduler\"][\"num_training_steps\"] = int(\n",
    "    num_training_steps\n",
    ")\n",
    "\n",
    "with open(f\"{log_dir}/config.json\", \"w\") as fp:\n",
    "    json.dump(train_config, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    epochs=epochs,  # train_config[\"num_epochs\"],\n",
    "    model=model,\n",
    "    device=device,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=test_loader,  # change to val-loader\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    use_lr_schedule=train_config[\"lr_schedule_config\"][\"use_lr_schedule\"],\n",
    "    scheduler_step=cosine_scheduler,\n",
    "    path=PATH,\n",
    "    log_freq=20,\n",
    "    config=train_config,\n",
    "    dataset_name=dataset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_obj = Inference(\n",
    "    model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    num_classes,\n",
    "    testset,\n",
    "    dataset_name,\n",
    "    labels_map=classes,\n",
    "    image_size=image_size,\n",
    "    channels=train_config[\"channels\"],\n",
    "    destination_dir=\"data\",\n",
    "    log_dir=log_dir,  # log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_obj.infer_plot_roc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_obj.generate_plot_confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d23d01cbf211985b3d816e736de6e478ad7ac216054a820b7342355fdb01c8c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('dlvr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
