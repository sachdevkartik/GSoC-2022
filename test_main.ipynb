{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "import copy\n",
    "from turtle import down\n",
    "import gdown\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torchinfo import summary\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "from models.cvt import CvT, EqCvT\n",
    "from typing import *\n",
    "from utils.util import (\n",
    "    make_directories,\n",
    "    seed_everything,\n",
    "    get_device,\n",
    "    init_logging_handler,\n",
    ")\n",
    "from utils.dataset import download_dataset, DeepLenseDataset, visualize_samples\n",
    "from utils.train import train\n",
    "from utils.inference import Inference\n",
    "from argparse import ArgumentParser\n",
    "from config.data_config import DATASET\n",
    "from config.eqcvt_config import EQCVT_CONFIG\n",
    "from utils.augmentation import get_transform_test, get_transform_train\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Model_I\"\n",
    "dataset_dir = \"data\"\n",
    "use_cuda = True\n",
    "\n",
    "classes = DATASET[f\"{dataset_name}\"][\"classes\"]\n",
    "\n",
    "train_config = EQCVT_CONFIG\n",
    "network_type = train_config[\"network_type\"]\n",
    "network_config = train_config[\"network_config\"]\n",
    "image_size = train_config[\"image_size\"]\n",
    "optimizer_config = train_config[\"optimizer_config\"]\n",
    "lr_schedule_config = train_config[\"lr_schedule_config\"]\n",
    "\n",
    "make_directories([dataset_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = DeepLenseDataset(\n",
    "    dataset_dir,\n",
    "    \"train\",\n",
    "    dataset_name,\n",
    "    transform=get_transform_train(upsample_size=387, final_size=129),\n",
    "    download=True,\n",
    ")  # get_transform_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = DeepLenseDataset(\n",
    "    dataset_dir,\n",
    "    \"test\",\n",
    "    dataset_name,\n",
    "    transform=get_transform_test(final_size=129),\n",
    "    download=True,\n",
    ")  # transform_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=42)\n",
    "device = get_device(use_cuda=use_cuda, cuda_idx=0)\n",
    "\n",
    "# logging\n",
    "current_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "log_dir = \"logger\"\n",
    "init_logging_handler(log_dir, current_time)\n",
    "\n",
    "PATH = os.path.join(f\"{log_dir}/checkpoint\", f\"{network_type}_{current_time}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=trainset, batch_size=train_config[\"batch_size\"], shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=testset, batch_size=train_config[\"batch_size\"], shuffle=True\n",
    ")\n",
    "\n",
    "visualize_samples(dataset=trainset, labels_map=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(classes)  # number of classes to be classified\n",
    "# image size (129x129)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Data: {len(trainset)}\")\n",
    "print(f\"Val Data: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EqCvT(\n",
    "    channels = train_config[\"channels\"],\n",
    "    num_classes = num_classes,\n",
    "    s1_emb_dim = network_config[\"s1_emb_dim\"],       # stage 1 - (same as above)\n",
    "    s1_emb_kernel = network_config[\"s1_emb_kernel\"],\n",
    "    s1_emb_stride = network_config[\"s1_emb_stride\"],\n",
    "    s1_proj_kernel = network_config[\"s1_proj_kernel\"],\n",
    "    s1_kv_proj_stride = network_config[\"s1_kv_proj_stride\"],\n",
    "    s1_heads = network_config[\"s1_heads\"],\n",
    "    s1_depth = network_config[\"s1_depth\"],\n",
    "    s1_mlp_mult = network_config[\"s1_mlp_mult\"],\n",
    "    mlp_last = network_config[\"mlp_last\"],\n",
    "    dropout = network_config[\"dropout\"],\n",
    "    sym_group = network_config[\"sym_group\"], \n",
    "    N = network_config[\"N\"],\n",
    "    image_size=image_size,\n",
    "    e2cc_mult_1 = network_config[\"e2cc_mult_1\"],\n",
    ").to(device)\n",
    "\n",
    "# print(v)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Parameter count:\", count_parameters(model))\n",
    "print(\"\\n\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=optimizer_config[\"lr\"], betas=optimizer_config[\"betas\"], weight_decay=optimizer_config[\"weight_decay\"])\n",
    "\n",
    "# scheduler\n",
    "step_lr = train_config[\"lr_schedule_config\"][\"step_lr\"]\n",
    "reduce_on_plateau = train_config[\"lr_schedule_config\"][\"reduce_on_plateau\"]\n",
    "\n",
    "scheduler_plateau = ReduceLROnPlateau(optimizer, 'min', factor=reduce_on_plateau[\"factor\"], patience=reduce_on_plateau[\"patience\"], threshold=reduce_on_plateau[\"threshold\"], verbose=reduce_on_plateau[\"verbose\"])\n",
    "scheduler_step = StepLR(optimizer, step_size=step_lr[\"step_size\"], gamma=step_lr[\"gamma\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    epochs = train_config[\"num_epochs\"],\n",
    "    model = model,\n",
    "    device = device,\n",
    "    train_loader = train_loader,\n",
    "    valid_loader = test_loader, # change to val-loader\n",
    "    criterion = criterion,\n",
    "    optimizer = optimizer,\n",
    "    use_lr_schedule = train_config[\"lr_schedule_config\"][\"use_lr_schedule\"],\n",
    "    scheduler_step = scheduler_step,\n",
    "    path = PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change the structure!\n",
    "infer_obj = Inference(\n",
    "    best_model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    num_classes,\n",
    "    testset,\n",
    "    dataset_name,\n",
    "    labels_map=classes,\n",
    "    image_size=image_size,\n",
    "    channels=train_config[\"channels\"],\n",
    "    destination_dir=\"data\",\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[inv_map[0], inv_map[1], inv_map[2]],title='Confusion matrix')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d23d01cbf211985b3d816e736de6e478ad7ac216054a820b7342355fdb01c8c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('dlvr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
